{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "623f7d4f-445a-4303-b926-054e23410c12",
   "metadata": {
    "kernelspec": {
     "display_name": "SparkMagic PySpark",
     "language": "python",
     "name": "pysparkkernel"
    },
    "language_info": {
     "codemirror_mode": {
      "name": "python",
      "version": 3
     },
     "file_extension": ".py",
     "mimetype": "text/x-python",
     "name": "pyspark",
     "pygments_lexer": "python3"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating EMR Serverless connection..\n",
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>1</td><td>00fo66g7dfntg90a</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"https://j-00fo66g7dfntg90a.dashboard.emr-serverless.us-east-1.amazonaws.com/?authToken=eDAxYDw_iWCVCH1v5n7HXUcpgBgsf4h5EtD08uK-HQ6leAulMuyD5hUdZt2XdJRd3RD2HpCweuBJI6sEZcr-bFf-BBjmthyAsWpYoEj6i5soLEvfWvTSi23z08kNbD-98lb1cNH9KO9cvyaSgCU5iv0dP65D-wDTSdGgdPc-UReevzNZULV9KCsieqyMTTtlpgqkwRV2Xkk0i5uOaHaPWJOc39dkcfLIBucKbgM4NZ-WxaZDzvup8eh_EwmHkkN09rJuzwyWnQuuG0TabtGPAw7nkFnpRreom5g2W6bhE2dACeOvcO-5G30W4LTRiH1dJTGkx_6TWOrXXN6wF8pO6M9_ZQHPjCTSL1xv_QHYhS8EkzyBlCisWIMESyEJ9cudb4QITv6SCVncMUOgjwyE3TUuAkUV4Y_wx5Y2tTLPOZUkLCQPMGnbcgzlta_RI4WuPv_dAYBmOA1xM-FguvB-zGaTpj-PY1WHtQR5ggw1LyTyYJfpuyUehEgxRJ0L6_KJRwhj4Br3hV__pxYUVylioX4FeS3u72KICEeXU7upQI9HInEwMpWAGi4MnXdo9kRcE57V0ja8-k0cwGYaq6_Zjd9MN0MezE3jYhYYVveZ7e07h-wp7hfq4E2PIZuH_yRulXCbIG0n6zinJgjBHrEHU-kVCwATzTShEwGFHD3peAshlHVdaYRRN2HuaZmsg5-tSWGeUft6Mh3mRasihAaaI4icAkJRhX8iIqyAIwJH5ORAxRxar-NQ-hzPWg6LUXzTLf2NmUjQmQTY9cVb_CQMgMivX2Nv9AE0YQDPZ_0wElgLLVyBhY0morWlfDr3HlkSdBDgvVozE4UqNV7JQ1-zeqQ7PO2yd-vwrHZvr7BHRqR10iFLb6weBTLdMZhtw88mcGyNF2XD-2aCbgdU60dueWP0bi4P8PDiS1De3ZE43dImgYdrBnejKzREsgAARWlqTZw.eyJraWQiOiJBUUlCQUhnTVJ1MlZyR2FFajR3bTc2dEZqMThGMUsyVFdZbkk4WXpxS0lRamg5YTZHZ0ZEUHhtR1hydW1ZMlh4SmNkaHJpd29BQUFBb2pDQm53WUpLb1pJaHZjTkFRY0dvSUdSTUlHT0FnRUFNSUdJQmdrcWhraUc5dzBCQndFd0hnWUpZSVpJQVdVREJBRXVNQkVFRERPaitHckl3UTUzQTY3VUhRSUJFSUJiM0RhYWNOMTZVaGkxUUwzMHJ5ekQ3REZsYWRzY3RpdHB0VEJOdG5uNEp2RW9HNU1VaXhSbDhEdnk0Qm1FaHhFVis2TGZkNmJDNFJkcEVkQUQxSjllSVczRHBNRlhqdGkvUkJBZ1VxVjlmQnI0V2xITlR5OEpYdy9mRmc9PSJ9\">Link</a></td><td><a target=\"_blank\" href=\"https://j-00fo66g7dfntg90a.dashboard.emr-serverless.us-east-1.amazonaws.com/logs/SPARK_DRIVER/stderr.gz?authToken=eDAx6sIjN8RO3w73RKPLpJAu_r__LKFClg6JeX_A2nL5WFWS50Z3Sh7kUC0Uw_FDZnRcZEVEefFfaxh-EE2kjh_Fla63jzj6vY4D-BU4V21kvsyi2s7qtYsg38uHFIlf9xNzhbs1-xygJPssex6ZrYvQFQ45FyyMkqZo1iUIqYrxvBQrtzmkbHwPdFgEUQmatUURy5DkThXCo0rUOie4v-0-7mpjuR13V5F6pUZZ142ILHxmbSXyX46W7t8sX3nNMAw1q_5JhOofZ7KrBaiJpqpG-wMxpUMTU5kEOoYypS7O6NMz_cXetdpiIWbPOFtbgd4Q0xrDI4fugg2jHG5FjqWpgXJpziBPODtOypb13tLSbQvdweDl7Vw0XFCg-7apKKGPZhANBsgOsgv6JAWwTYpAoVZ43Jk17Pc4u4g_EuHXljTE0Uy2xg3G3BaZlWyTH8VYMNd_ofx-XNYL-3WHiGGIevlDbLOR5B4veO9pBI2npYrI1rJoEsbrl5hU3pTlwGjVe5Kt2NK0hs4dpblqSTAY3_QoNVXOO6zvzbiXiNNV13TXXSftsmcVXb-sJNPta0lBKEzfUeu-2A8kbQxkt9NBPigN1XwWc8qGwYNfRTN3cdeWkPzhx8_jbfCa9omEZxFeRvM6FqyI_I5JE9yUh30EyXtvAOYQCgpsHJLYyqd1dLAthANd5qaqy-o3nFRYcQpZ8kMMemPUpPEhTp9Lo-hs9XWXtYNziZ0gJtLyjoUXkYDpZ1AAgqpgr6DqRzVvcPsj14D8P3wuQgp0IXA2dduSjK7mwGFTZ_kfOjkESt5zp2SdCRsk6DOl_RKP6SZvJQX4A7ljFA5SK6pw_r7BjqRTGuk6f0BPypbvjRIBqsTy9tpDN8rxbtRt1vy2HzRIZF4QSoRoao_dkLalLrneATbnfOOSQSVkwKI_AjOXpXd8YPBfG6nZI1IyDeevEUh5P3g.eyJraWQiOiJBUUlCQUhnTVJ1MlZyR2FFajR3bTc2dEZqMThGMUsyVFdZbkk4WXpxS0lRamg5YTZHZ0dlUDdEa0dUaGxnZ3BmWXJhUmFjekdBQUFBb2pDQm53WUpLb1pJaHZjTkFRY0dvSUdSTUlHT0FnRUFNSUdJQmdrcWhraUc5dzBCQndFd0hnWUpZSVpJQVdVREJBRXVNQkVFREJnSlpOdjRhbnV5NlJTVU9BSUJFSUJiZjQ1MHA2T0lFMXRKdkxwSUlwT1BWMUxiWmdqdmtoR2lrU3VLUDZSbC9MSWtHbmZod3lKZTcxVnc1bTc5bmpPangzT1Q5cDM4UzJyQlVFVERjeHRMMk9uUldOemtEay90dEw0QlJ4TitOeTdFTFJad1NCalJOK1hrZkE9PSJ9\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "%load_ext sagemaker_studio_analytics_extension.magics\n",
    "%sm_analytics emr-serverless connect --application-id 00fo38nsirh68609 --language python --emr-execution-role-arn arn:aws:iam::442426877041:role/service-role/AmazonEMRStudio_RuntimeRole_1731016215290"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d84ac8-759b-4dcc-a5a3-3bdc37b66767",
   "metadata": {},
   "source": [
    "no need of: from pyspark.sql import SparkSession\n",
    "\n",
    "it happens above automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b413311f-fefa-44fb-89a6-79ee5a006107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "from urllib.parse import quote_plus\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb62f135-ebc1-45ff-908c-cacc8f8cab8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s3_temp_dir = \"s3://apartment-pricing/temp/\"\n",
    "output_s3_path = \"s3://apartment-pricing/preprocessed/data/parquet/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51591916-9fb4-4469-8d17-08d70c055072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE): 250.32739887349678\n",
      "Coefficients: [1.5029013947563223,149.1467512957859,197.3680103676724,99.88583351752915,79.90852853641567,43.724228576573914,100.11736460990436,99.92473243385216,49.83787050411398]\n",
      "Intercept: 6.2358234630259615\n",
      "+--------------------+-------+------------------+\n",
      "|            features|  label|        prediction|\n",
      "+--------------------+-------+------------------+\n",
      "|[400.0,2.0,3.0,0....|2492.11|2146.4826178283765|\n",
      "|[400.0,2.0,3.0,0....|2492.11|2146.4826178283765|\n",
      "|[400.0,2.0,3.0,0....|2492.11|2146.4826178283765|\n",
      "|[400.0,2.0,3.0,0....|2492.11|2146.4826178283765|\n",
      "|[400.0,2.0,3.0,0....|2492.11|2146.4826178283765|\n",
      "|[400.0,2.0,3.0,0....|2492.11|2146.4826178283765|\n",
      "|[400.0,2.0,3.0,0....|2492.11|2146.4826178283765|\n",
      "|[400.0,2.0,3.0,0....|2492.11|2146.4826178283765|\n",
      "|[400.0,2.0,3.0,0....|2492.11|2146.4826178283765|\n",
      "|[400.0,2.0,3.0,0....|2492.11|2146.4826178283765|\n",
      "|[400.0,2.0,3.0,0....|2492.11|2146.4826178283765|\n",
      "|[400.0,2.0,3.0,0....|2492.11|2146.4826178283765|\n",
      "|[400.0,2.0,3.0,0....|2492.11|2146.4826178283765|\n",
      "|[400.0,2.0,3.0,0....|2492.11|2146.4826178283765|\n",
      "|[400.0,2.0,3.0,0....|2492.11|2146.4826178283765|\n",
      "|[400.0,2.0,3.0,0....|2492.11|2146.4826178283765|\n",
      "|[400.0,2.0,3.0,0....|2492.11|2146.4826178283765|\n",
      "|[400.0,2.0,3.0,0....|2492.11|2146.4826178283765|\n",
      "|[400.0,2.0,3.0,0....|2492.11|2146.4826178283765|\n",
      "|[400.0,2.0,3.0,0....|2492.11|2146.4826178283765|\n",
      "+--------------------+-------+------------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "# source s3 parquet, pyspark.ml framework obviously built for cluster, further processing on EMR cluster\n",
    "# model training, prediction and evaluation -- dont think distribution was necessary but works\n",
    "#### check training from console\n",
    "#### training job using sdk\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Load preprocessed data\n",
    "preprocessed_data = spark.read.parquet(output_s3_path)\n",
    "\n",
    "# Select features and target variable\n",
    "# Drop 'rent' from the features and use it as the label\n",
    "feature_columns = [\n",
    "    \"squarefootage\", \"numrooms\", \"numbathrooms\", \"hasbalcony\", \n",
    "    \"hasgymaccess\", \"hasparking\", \"neighborhoodsafetyindex\", \n",
    "    \"walkscore\", \"schoolrating\"\n",
    "]\n",
    "\n",
    "# Ensure boolean fields are numeric (if necessary)\n",
    "preprocessed_data = preprocessed_data.withColumn(\"hasbalcony\", col(\"hasbalcony\").cast(\"int\"))\n",
    "preprocessed_data = preprocessed_data.withColumn(\"hasgymaccess\", col(\"hasgymaccess\").cast(\"int\"))\n",
    "preprocessed_data = preprocessed_data.withColumn(\"hasparking\", col(\"hasparking\").cast(\"int\"))\n",
    "\n",
    "# Assemble features into a vector\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "assembled_data = assembler.transform(preprocessed_data)\n",
    "\n",
    "# Prepare the final dataset with features and label\n",
    "final_data = assembled_data.select(\"features\", col(\"rent\").alias(\"label\"))\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_data, test_data = final_data.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Train a linear regression model\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"label\")\n",
    "model = lr.fit(train_data)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "# Evaluate using RMSE (Root Mean Squared Error)\n",
    "evaluator = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "\n",
    "# Optionally print coefficients and intercept\n",
    "print(f\"Coefficients: {model.coefficients}\")\n",
    "print(f\"Intercept: {model.intercept}\")\n",
    "\n",
    "# Show some predictions\n",
    "predictions.select(\"features\", \"label\", \"prediction\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59e3d822-ab6b-4194-9af8-369ceff69303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Paths to save model and pipeline\n",
    "model_path = \"s3://apartment-pricing/model/linear_regression/parquet_1/\"\n",
    "pipeline_path = \"s3://apartment-pricing/pipeline/linear_regression/parquet_1/vector_assembler/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66bddcd1-c1f7-4981-939f-8cf86cde76f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save the assembler for reuse during inference\n",
    "assembler.write().overwrite().save(pipeline_path)\n",
    "\n",
    "# Save the trained model\n",
    "model.write().overwrite().save(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4311bb14-02d7-4359-ada2-0f03016adb54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+\n",
      "|            features|       prediction|\n",
      "+--------------------+-----------------+\n",
      "|[750.0,2.0,1.0,1....|3851.728029591021|\n",
      "|[1200.0,3.0,2.0,0...|4924.521504403287|\n",
      "+--------------------+-----------------+"
     ]
    }
   ],
   "source": [
    "## batch predictions from saved model\n",
    "\n",
    "from pyspark.ml.regression import LinearRegressionModel\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# Load the saved model\n",
    "model = LinearRegressionModel.load(model_path)\n",
    "\n",
    "# Load the saved assembler\n",
    "assembler = VectorAssembler.load(pipeline_path)\n",
    "\n",
    "# Simulate new data for inference (replace with your actual data)\n",
    "new_data = spark.createDataFrame([\n",
    "    (750, 2, 1, 1, 1, 1, 8.5, 7.5, 8),  # Example row\n",
    "    (1200, 3, 2, 0, 1, 1, 9.0, 8.0, 9)  # Example row\n",
    "], [\n",
    "    \"squarefootage\", \"numrooms\", \"numbathrooms\", \"hasbalcony\", \n",
    "    \"hasgymaccess\", \"hasparking\", \"neighborhoodsafetyindex\", \n",
    "    \"walkscore\", \"schoolrating\"\n",
    "])\n",
    "\n",
    "# Ensure all fields are numeric and assemble features\n",
    "new_data = new_data.withColumn(\"hasbalcony\", col(\"hasbalcony\").cast(\"int\"))\n",
    "new_data = new_data.withColumn(\"hasgymaccess\", col(\"hasgymaccess\").cast(\"int\"))\n",
    "new_data = new_data.withColumn(\"hasparking\", col(\"hasparking\").cast(\"int\"))\n",
    "\n",
    "new_data_assembled = assembler.transform(new_data)\n",
    "\n",
    "# Predict rent using the loaded model\n",
    "predictions = model.transform(new_data_assembled)\n",
    "\n",
    "# Show predictions\n",
    "predictions.select(\"features\", \"prediction\").show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SparkMagic PySpark",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
